<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta charset="UTF-8">
  <title>Zachary Dascil - Katakana-Classifier</title>
  <meta name="description" content="Zachary Dascil's project that uses convolution neural networks to
  classify images of Japanese katakana characters.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Arvo&display=swap" rel="stylesheet">
  <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
  <link rel="manifest" href="images/site.webmanifest">
  <link rel="mask-icon" href="images/safari-pinned-tab.svg" color="#2b5797">
  <link rel="shortcut icon" href="images/favicon.ico">
  <meta name="msapplication-TileColor" content="#2b5797">
  <meta name="msapplication-config" content="images/browserconfig.xml">
  <meta name="theme-color" content="#2b5797">
  <meta name="robots" content="noindex, nofollow">
  <meta property="og:url" content="https://www.zacharydascil.com/resume" />
  <meta property="og:title" content="Zachary Dascil - Katakana Classifier" />
  <meta property="og:description"
    content="This is Zachary Dascil's personal website, showcasing his credentials and projects." />
  <meta property="og:site_name" content="Zachary Dascil" />
  <meta property="og:image" content="https://www.zacharydascil.com/images/ogimage.png" />
  <meta property="og:type" content="website" />
  <meta property="og:locale" content="en_US" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
  <link rel="stylesheet" href="../style.css">
</head>

<body>
  <nav class=" navbar navbar-expand-lg head_foot_bar">
    <div class="left-align">
      <a href="../"><img id="logo" src="../images/logo.png" alt="logo"></a>
    </div>
    <button class="navbar-dark navbar-toggler" type="button" data-bs-toggle="collapse"
      data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false"
      aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ms-auto">
        <li class="nav-item"><a href="../resume" class="nav-link navbar-link">Resume</a></li>
        <li class="nav-item"><a href="../projects" class="nav-link navbar-link">Projects</a></li>
        <li class="nav-item"><a href="../contact" class="nav-link navbar-link">Contact</a></li>
      </ul>
    </div>
  </nav>
  <main class="container">
    <h1 class="text-center pt-5 pb-4">Katakana Classifier</h1>
    <h2>Overview</h2>
    <p>This project explores the use of Convolution Neural Networks (CNN) to classify images of handwritten Japanese
      Katakana characters.
      Six different CNN models were used to classify the 46 main Katakana characters, exluding the characters with
      dakuten (゛) and handakuten (゜).
      The most accurate model achieved a testing accuracy of 99.15%. For a similar experiment, check out
      <a href="http://cs231n.stanford.edu/reports/2016/pdfs/262_Report.pdf">this report</a> (1) by Charlie Tsai.
    </p>
    <h2>Problem and Motivation</h2>
    <p>During my trips to Japan, I would come across words I did could not comprehend, whether it was due to the lack
      of my vocabulary or I was unable to read the characters.
      I would then spend minutes trying to find the meaning of characters to then find out the meaning of the word.
      This project will lay the groundwork to be able to classify words using live input.
    </p>
    <h2>Dataset and Implementation</h2>
    <p>
      The datasets used were the ETL-1 and ETL-6 datasets from the ETL database (2) found
      <a href="http://etlcdb.db.aist.go.jp/">here</a>. The database contains 1.2 million greyscale images of handwritten
      and
      machine-generated hiragana, katakana, and kanji characters of various resolutions. The two datasets I used have
      around 2,800 images of each katakana character with the resolution of 63x64. Each dataset was in a different
      binary formats but, an image extractor was created by choo (3) which can be found
      <a href="https://github.com/choo/etlcdb-image-extractor">here</a>. A sample of the images can be seen below.
    </p>
    <img src="assets/katakana-classifier/img/random_katakana.png" alt="random katakana image data" class="mx-auto d-block img-fluid mt-3 mb-4">
    <p>The images were sorted by their unicode and placed into their respective folders. A method to transform these
      folders into a dataset was created by Utkarsh Garg (4) which can be found
      <a href="towardsdatascience.com/custom-dataset-in-pytorch-part-1-images-2df3152895">here</a> however, for my
      project, some
      modules were changed and some of the code was modified to better fit my design.
    </p>
    <h2>Models</h2>
    <p>
      For my CNN models, I used Pytorch and used Pytorch's nn's Sequential function to organize my models. I used the
      optimizer Adam with a learning rate of 0.0001 and the CrossEntropyLoss function for all of my models. All models
      trained were for 100 epochs except for the Basic model which trained for 40 epochs due to overfitting issues. With
      the exception of the final fully-connected layer, all fully-connected layers had a dropout rate of 50% while
      convolution layers had a dropout rate of 15% to prevent overfitting. Finally the activation functions for all the
      layers were ReLU with the exception of the output layer which used LogSoftMax.
    </p>
    <p>
      Below I showcase a couple of my implementations:
    </p>
    <h3>Basic Model</h3>
    <table class="center mt-3 mb-4">
      <tr>
        <th>Layer</th>
        <th class="left-right-padding">Activation Function</th>
        <th>Dropout Rate</th>
      </tr>
      <tr>
        <td>Conv2d(1,32,5)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.15</td>
      </tr>
      <tr>
        <td>MaxPool2d(2)</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Flatten()</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Linear(27840,46)</td>
        <td class="left-right-padding">LogSoftMax(dim=1)</td>
        <td>0.0</td>
      </tr>
    </table>
    <h3>Densest Model</h3>
    <table class="center mt-3 mb-4">
      <tr>
        <th>Layer</th>
        <th class="left-right-padding">Activation Function</th>
        <th>Dropout Rate</th>
      </tr>
      <tr>
        <td>Conv2d(1,32,5)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.15</td>
      </tr>
      <tr>
        <td>MaxPool2d(2)</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Conv2d(32,64,5)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.15</td>
      </tr>
      <tr>
        <td>MaxPool2d(2)</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Conv2d(64,128,5)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.15</td>
      </tr>
      <tr>
        <td>MaxPool2d(2)</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Flatten()</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Linear(2048,512)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.5</td>
      </tr>
      <tr>
        <td>Linear(512,128)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.5</td>
      </tr>
      <tr>
        <td>Linear(128,46)</td>
        <td class="left-right-padding">LogSoftMax(dim=1)</td>
        <td>0.0</td>
      </tr>
    </table>
    <h3 class="">Conv22 Model</h3>
    <table class="center mt-3 mb-4">
      <tr>
        <th>Layer</th>
        <th class="left-right-padding">Activation Function</th>
        <th>Dropout Rate</th>
      </tr>
      <tr>
        <td>Conv2d(1,32,5)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.15</td>
      </tr>
      <tr>
        <td>Conv2d(32,32,5)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.15</td>
      </tr>
      <tr>
        <td>MaxPool2d(2)</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Conv2d(32,64,5)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.15</td>
      </tr>
      <tr>
        <td>Conv2d(64,64,5)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.15</td>
      </tr>
      <tr>
        <td>MaxPool2d(2)</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Flatten()</td>
        <td class="left-right-padding"></td>
        <td></td>
      </tr>
      <tr>
        <td>Linear(2048,512)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.5</td>
      </tr>
      <tr>
        <td>Linear(512,128)</td>
        <td class="left-right-padding">ReLU</td>
        <td>0.5</td>
      </tr>
      <tr>
        <td>Linear(128,46)</td>
        <td class="left-right-padding">LogSoftMax(dim=1)</td>
        <td>0.0</td>
      </tr>
    </table>
    <p>
      For the next four models, more convolution and fully-connected layers were added with the largest model having 4
      convolution layers and 3 fully-connected layers.
    </p>
    <p>
      The last model was loosely based on Nouman's implementation of the LeNet-5 model (5) found <a
        href="https://blog.paperspace.com/writing-lenet5-from-scratch-in-python/">here</a>.
    </p>
    <h2>Results</h2>
    <p>
      To measure the accuracy of my models, I took the percentage, rounded to decimal places, of the amount of images
      the models correctly predicted, based on the label with the highest probablity, divided by the total amount of
      pictures viewed.
    </p>
    <table class="center mt-3 mb-4">
      <tr>
        <th>Model Name</th>
        <th class="left-right-padding">Training Accuracy</th>
        <th class="left-right-padding">Validation Accuracy</th>
        <th>Testing Accuracy</th>
      </tr>
      <tr>
        <td>LeNet-5</td>
        <td class="left-right-padding">92.41%</td>
        <td class="left-right-padding">91.25%</td>
        <td>92.62%</td>
      </tr>
      <tr>
        <td>Basic</td>
        <td class="left-right-padding">99.85%</td>
        <td class="left-right-padding">92.33%</td>
        <td>94.57%</td>
      </tr>
      <tr>
        <td>Complex</td>
        <td class="left-right-padding">97.51%</td>
        <td class="left-right-padding">95.72%</td>
        <td>96.60%</td>
      </tr>
      <tr>
        <td>Complex Denser</td>
        <td class="left-right-padding">94.29%</td>
        <td class="left-right-padding">92.06%</td>
        <td>93.21%</td>
      </tr>
      <tr>
        <td>Complex Densest</td>
        <td class="left-right-padding">99.64%</td>
        <td class="left-right-padding">98.65%</td>
        <td>99.09%</td>
      </tr>
      <tr>
        <td>Conv22</td>
        <td class="left-right-padding">99.63%</td>
        <td class="left-right-padding">98.55%</td>
        <td>99.16%</td>
      </tr>
    </table>
    <p>Below is a graph of Complex Densest's relationship between epochs and accuracy.</p>
    <img src="assets/katakana-classifier/img/epochaccuracygraph.png" alt="epoch versus accuracy graph" class="mx-auto d-block img-fluid mt-3 mb-4">
    <p>
      Based on the testing accuracies, the amount of convolution layers play a larger role with the accuracy than the
      fully-connected as seen with the Complex Densest and Conv 2 models which had 3 and 4 convolution layers
      respectively. It appears that there is diminishing returns after the third convolution layers which brings up the
      trade-off between number of convolution layers and time when other methods of increasing accuracy exist such as
      hyperparameter tuning. Adding more fully-connected layers do not seem to add to the model's accuracy. The Complex
      and Complex Denser models are the same model with the Complex Denser model having an extra fully-connected layer.
      ## Final Thoughts and Project's Future
    </p>
    <p>
      Going through the process of working on this project, I gained a better understanding of the use of CNNs and its
      strengths and weaknesses. While accuracy increases with more convolution layers, the training time also increases.
      Also, the resolution of the photos need to be constant to transition from a convolution layer to the
      fully-connected layer.
    </p>
    <h2>References</h2>

    <p>(1) Tsai, Charlie. Recognizing Handwritten Japanese Characters Using Deep Convolutional Neural Networks.</p>

    <p>(2) National Institute of Advanced Industrial Science and Technology (AIST), and Japan Electronics and
      Information Technology Industries Association. “Etlcdb.” Etlcdb, etlcdb.db.aist.go.jp/. Accessed 13 Mar. 2022.
    </p>

    <p>(3) choo. “ETLCDB Image Extractor.” GitHub, 16 July 2021, github.com/choo/etlcdb-image-extractor. Accessed 13
      Mar. 2022.</p>

    <p>(4) Garg, Utkarsh. “Custom Dataset in Pytorch —Part 1. Images.” Medium, 2 Oct. 2021,
      towardsdatascience.com/custom-dataset-in-pytorch-part-1-images-2df3152895. Accessed 13 Mar. 2022.</p>

    <p>(5) Nouman. “Writing LeNet5 from Scratch in PyTorch.” Paperspace Blog, 9 Jan. 2022,
      blog.paperspace.com/writing-lenet5-from-scratch-in-python/. Accessed 13 Mar. 2022.</p>

  </main>
  <footer class="head_foot_bar mt-3">
    <div class="one-flex">
      <p></p>
    </div>
    <div>
      <a href="https://www.linkedin.com/in/zacharydascil"><img class="social-media-logo"
          src="../images/linkedinlogo.png" alt="logo"></a>
    </div>
    <div class="one-flex"></div>
  </footer>
</body>

</html>